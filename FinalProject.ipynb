{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0542f023",
   "metadata": {},
   "source": [
    "# Import Dataset\n",
    "https://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f582fdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10)\n",
      "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
      "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_gz_json(path, max_records=None):\n",
    "    data = []\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            data.append(json.loads(line))\n",
    "            if max_records and (i + 1) >= max_records:\n",
    "                break\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load first 100,000 reviews\n",
    "reviews_df = load_gz_json('data/Electronics.jsonl.gz', max_records=100000)\n",
    "print(reviews_df.shape)\n",
    "print(reviews_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba71f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 16)\n",
      "Index(['main_category', 'title', 'average_rating', 'rating_number', 'features',\n",
      "       'description', 'price', 'images', 'videos', 'store', 'categories',\n",
      "       'details', 'parent_asin', 'bought_together', 'subtitle', 'author'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "meta_df = load_gz_json('data/meta_Electronics.jsonl.gz', max_records=100000)\n",
    "print(meta_df.shape)\n",
    "print(meta_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62874c73",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f5bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\vgoli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\vgoli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\vgoli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vgoli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vgoli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vgoli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\VGoli\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\VGoli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\VGoli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VGoli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\VGoli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab') \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return tokens\n",
    "\n",
    "reviews_df['tokens'] = reviews_df['text'].fillna('').apply(preprocess)\n",
    "reviews_df['clean_text'] = reviews_df['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab9aeb",
   "metadata": {},
   "source": [
    "# Sentiment Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c07bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_label(rating):\n",
    "    if rating >= 4:\n",
    "        return 1   # positive\n",
    "    elif rating <= 2:\n",
    "        return 0   # negative\n",
    "    else:\n",
    "        return None  # neutral / skip\n",
    "\n",
    "reviews_df['label'] = reviews_df['rating'].apply(get_sentiment_label)\n",
    "reviews_df = reviews_df.dropna(subset=['label'])  # remove neutral or missing\n",
    "reviews_df['label'] = reviews_df['label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3abea0",
   "metadata": {},
   "source": [
    "# Logistic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f80bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "X = reviews_df['clean_text'].values\n",
    "y = reviews_df['label'].values\n",
    "\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "def run_log_reg(X, y, vectorizer, model, k=5):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        preds = model.predict(X_test_vec)\n",
    "\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        scores.append((acc, f1))\n",
    "        print(f\"Fold {fold + 1}: Accuracy={acc:.4f}, F1={f1:.4f}\")\n",
    "        print(classification_report(y_test, preds, digits=3))\n",
    "\n",
    "    avg_acc = np.mean([s[0] for s in scores])\n",
    "    print(\"Avg Accuracy:\", avg_acc)\n",
    "    print(\"Avg F1 Score:\", np.mean([s[1] for s in scores]))\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531c3af",
   "metadata": {},
   "source": [
    "# 10 different configs for ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84463a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Configuration 1: {'max_features': 10000}\n",
      "Fold 1: Accuracy=0.9286, F1=0.9599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.856     0.554     0.673      2462\n",
      "           1      0.935     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.896     0.770     0.816     18574\n",
      "weighted avg      0.925     0.929     0.922     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9280, F1=0.9596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.853     0.552     0.670      2462\n",
      "           1      0.935     0.985     0.960     16112\n",
      "\n",
      "    accuracy                          0.928     18574\n",
      "   macro avg      0.894     0.769     0.815     18574\n",
      "weighted avg      0.924     0.928     0.921     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9259, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.549     0.663      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.885     0.766     0.810     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9284, F1=0.9598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.855     0.553     0.672      2461\n",
      "           1      0.935     0.986     0.960     16113\n",
      "\n",
      "    accuracy                          0.928     18574\n",
      "   macro avg      0.895     0.770     0.816     18574\n",
      "weighted avg      0.925     0.928     0.922     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9256, F1=0.9582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.834     0.548     0.661      2461\n",
      "           1      0.934     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.926     18573\n",
      "   macro avg      0.884     0.766     0.810     18573\n",
      "weighted avg      0.921     0.926     0.919     18573\n",
      "\n",
      "Avg Accuracy: 0.9272954198853574\n",
      "Avg F1 Score: 0.9591814293639678\n",
      "Running Configuration 2: {'max_features': 5000}\n",
      "Fold 1: Accuracy=0.9294, F1=0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.857     0.561     0.678      2462\n",
      "           1      0.936     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.896     0.773     0.819     18574\n",
      "weighted avg      0.926     0.929     0.923     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9283, F1=0.9597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.849     0.559     0.674      2462\n",
      "           1      0.936     0.985     0.960     16112\n",
      "\n",
      "    accuracy                          0.928     18574\n",
      "   macro avg      0.892     0.772     0.817     18574\n",
      "weighted avg      0.924     0.928     0.922     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9260, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.552     0.664      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.884     0.768     0.811     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9283, F1=0.9597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.846     0.561     0.675      2461\n",
      "           1      0.936     0.984     0.960     16113\n",
      "\n",
      "    accuracy                          0.928     18574\n",
      "   macro avg      0.891     0.773     0.817     18574\n",
      "weighted avg      0.924     0.928     0.922     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9255, F1=0.9582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.548     0.661      2461\n",
      "           1      0.934     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.926     18573\n",
      "   macro avg      0.884     0.765     0.810     18573\n",
      "weighted avg      0.921     0.926     0.919     18573\n",
      "\n",
      "Avg Accuracy: 0.9275107735228808\n",
      "Avg F1 Score: 0.9592779271063454\n",
      "Running Configuration 3: {'max_features': 100000}\n",
      "Fold 1: Accuracy=0.9289, F1=0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.556     0.674      2462\n",
      "           1      0.936     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.897     0.771     0.817     18574\n",
      "weighted avg      0.925     0.929     0.922     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9273, F1=0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.544     0.665      2462\n",
      "           1      0.934     0.986     0.959     16112\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.894     0.765     0.812     18574\n",
      "weighted avg      0.923     0.927     0.920     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9259, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.549     0.663      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.885     0.766     0.810     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9275, F1=0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.549     0.667      2461\n",
      "           1      0.935     0.985     0.959     16113\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.893     0.767     0.813     18574\n",
      "weighted avg      0.924     0.927     0.921     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9245, F1=0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.538     0.654      2461\n",
      "           1      0.933     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.925     18573\n",
      "   macro avg      0.883     0.761     0.806     18573\n",
      "weighted avg      0.920     0.925     0.917     18573\n",
      "\n",
      "Avg Accuracy: 0.9268108594172453\n",
      "Avg F1 Score: 0.9589232089818701\n",
      "Running Configuration 4: {'max_features': 500000}\n",
      "Fold 1: Accuracy=0.9289, F1=0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.556     0.674      2462\n",
      "           1      0.936     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.897     0.771     0.817     18574\n",
      "weighted avg      0.925     0.929     0.922     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9273, F1=0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.544     0.665      2462\n",
      "           1      0.934     0.986     0.959     16112\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.894     0.765     0.812     18574\n",
      "weighted avg      0.923     0.927     0.920     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9259, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.549     0.663      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.885     0.766     0.810     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9275, F1=0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.549     0.667      2461\n",
      "           1      0.935     0.985     0.959     16113\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.893     0.767     0.813     18574\n",
      "weighted avg      0.924     0.927     0.921     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9245, F1=0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.538     0.654      2461\n",
      "           1      0.933     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.925     18573\n",
      "   macro avg      0.883     0.761     0.806     18573\n",
      "weighted avg      0.920     0.925     0.917     18573\n",
      "\n",
      "Avg Accuracy: 0.9268108594172453\n",
      "Avg F1 Score: 0.9589232089818701\n",
      "Running Configuration 5: {'ngram_range': (1, 2)}\n",
      "Fold 1: Accuracy=0.9241, F1=0.9577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.885     0.491     0.632      2462\n",
      "           1      0.927     0.990     0.958     16112\n",
      "\n",
      "    accuracy                          0.924     18574\n",
      "   macro avg      0.906     0.741     0.795     18574\n",
      "weighted avg      0.922     0.924     0.915     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9234, F1=0.9573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.890     0.481     0.625      2462\n",
      "           1      0.926     0.991     0.957     16112\n",
      "\n",
      "    accuracy                          0.923     18574\n",
      "   macro avg      0.908     0.736     0.791     18574\n",
      "weighted avg      0.921     0.923     0.913     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9221, F1=0.9566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.882     0.476     0.618      2461\n",
      "           1      0.925     0.990     0.957     16113\n",
      "\n",
      "    accuracy                          0.922     18574\n",
      "   macro avg      0.903     0.733     0.787     18574\n",
      "weighted avg      0.919     0.922     0.912     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9262, F1=0.9589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.897     0.501     0.643      2461\n",
      "           1      0.929     0.991     0.959     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.913     0.746     0.801     18574\n",
      "weighted avg      0.924     0.926     0.917     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9216, F1=0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.875     0.476     0.616      2461\n",
      "           1      0.925     0.990     0.956     16112\n",
      "\n",
      "    accuracy                          0.922     18573\n",
      "   macro avg      0.900     0.733     0.786     18573\n",
      "weighted avg      0.919     0.922     0.911     18573\n",
      "\n",
      "Avg Accuracy: 0.9234835959167835\n",
      "Avg F1 Score: 0.9573709078896278\n",
      "Running Configuration 6: {'use_idf': False}\n",
      "Fold 1: Accuracy=0.9254, F1=0.9581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.839     0.541     0.658      2462\n",
      "           1      0.933     0.984     0.958     16112\n",
      "\n",
      "    accuracy                          0.925     18574\n",
      "   macro avg      0.886     0.762     0.808     18574\n",
      "weighted avg      0.921     0.925     0.918     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9273, F1=0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.547     0.666      2462\n",
      "           1      0.934     0.985     0.959     16112\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.893     0.766     0.813     18574\n",
      "weighted avg      0.923     0.927     0.920     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9252, F1=0.9580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.839     0.539     0.656      2461\n",
      "           1      0.933     0.984     0.958     16113\n",
      "\n",
      "    accuracy                          0.925     18574\n",
      "   macro avg      0.886     0.762     0.807     18574\n",
      "weighted avg      0.921     0.925     0.918     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9279, F1=0.9595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.553     0.670      2461\n",
      "           1      0.935     0.985     0.960     16113\n",
      "\n",
      "    accuracy                          0.928     18574\n",
      "   macro avg      0.893     0.769     0.815     18574\n",
      "weighted avg      0.924     0.928     0.921     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9237, F1=0.9571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.826     0.537     0.651      2461\n",
      "           1      0.933     0.983     0.957     16112\n",
      "\n",
      "    accuracy                          0.924     18573\n",
      "   macro avg      0.879     0.760     0.804     18573\n",
      "weighted avg      0.919     0.924     0.917     18573\n",
      "\n",
      "Avg Accuracy: 0.9258848245139873\n",
      "Avg F1 Score: 0.9584055610613579\n",
      "Running Configuration 7: {'stop_words': None}\n",
      "Fold 1: Accuracy=0.9289, F1=0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.556     0.674      2462\n",
      "           1      0.936     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.897     0.771     0.817     18574\n",
      "weighted avg      0.925     0.929     0.922     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9273, F1=0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.544     0.665      2462\n",
      "           1      0.934     0.986     0.959     16112\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.894     0.765     0.812     18574\n",
      "weighted avg      0.923     0.927     0.920     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9259, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.549     0.663      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.885     0.766     0.810     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9275, F1=0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.549     0.667      2461\n",
      "           1      0.935     0.985     0.959     16113\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.893     0.767     0.813     18574\n",
      "weighted avg      0.924     0.927     0.921     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9245, F1=0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.538     0.654      2461\n",
      "           1      0.933     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.925     18573\n",
      "   macro avg      0.883     0.761     0.806     18573\n",
      "weighted avg      0.920     0.925     0.917     18573\n",
      "\n",
      "Avg Accuracy: 0.9268108594172453\n",
      "Avg F1 Score: 0.9589232089818701\n",
      "Running Configuration 8: {'lowercase': True}\n",
      "Fold 1: Accuracy=0.9289, F1=0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.556     0.674      2462\n",
      "           1      0.936     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.897     0.771     0.817     18574\n",
      "weighted avg      0.925     0.929     0.922     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9273, F1=0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.544     0.665      2462\n",
      "           1      0.934     0.986     0.959     16112\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.894     0.765     0.812     18574\n",
      "weighted avg      0.923     0.927     0.920     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9259, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.549     0.663      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.885     0.766     0.810     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9275, F1=0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.549     0.667      2461\n",
      "           1      0.935     0.985     0.959     16113\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.893     0.767     0.813     18574\n",
      "weighted avg      0.924     0.927     0.921     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9245, F1=0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.538     0.654      2461\n",
      "           1      0.933     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.925     18573\n",
      "   macro avg      0.883     0.761     0.806     18573\n",
      "weighted avg      0.920     0.925     0.917     18573\n",
      "\n",
      "Avg Accuracy: 0.9268108594172453\n",
      "Avg F1 Score: 0.9589232089818701\n",
      "Running Configuration 9: {'lowercase': False}\n",
      "Fold 1: Accuracy=0.9289, F1=0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.556     0.674      2462\n",
      "           1      0.936     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.897     0.771     0.817     18574\n",
      "weighted avg      0.925     0.929     0.922     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9273, F1=0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.544     0.665      2462\n",
      "           1      0.934     0.986     0.959     16112\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.894     0.765     0.812     18574\n",
      "weighted avg      0.923     0.927     0.920     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9259, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.549     0.663      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.885     0.766     0.810     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9275, F1=0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.549     0.667      2461\n",
      "           1      0.935     0.985     0.959     16113\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.893     0.767     0.813     18574\n",
      "weighted avg      0.924     0.927     0.921     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9245, F1=0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.538     0.654      2461\n",
      "           1      0.933     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.925     18573\n",
      "   macro avg      0.883     0.761     0.806     18573\n",
      "weighted avg      0.920     0.925     0.917     18573\n",
      "\n",
      "Avg Accuracy: 0.9268108594172453\n",
      "Avg F1 Score: 0.9589232089818701\n",
      "Running Configuration 10: {'max_df': 0.9}\n",
      "Fold 1: Accuracy=0.9289, F1=0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.556     0.674      2462\n",
      "           1      0.936     0.986     0.960     16112\n",
      "\n",
      "    accuracy                          0.929     18574\n",
      "   macro avg      0.897     0.771     0.817     18574\n",
      "weighted avg      0.925     0.929     0.922     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9273, F1=0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.544     0.665      2462\n",
      "           1      0.934     0.986     0.959     16112\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.894     0.765     0.812     18574\n",
      "weighted avg      0.923     0.927     0.920     18574\n",
      "\n",
      "Fold 3: Accuracy=0.9259, F1=0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.549     0.663      2461\n",
      "           1      0.935     0.983     0.958     16113\n",
      "\n",
      "    accuracy                          0.926     18574\n",
      "   macro avg      0.885     0.766     0.810     18574\n",
      "weighted avg      0.921     0.926     0.919     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9275, F1=0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.549     0.667      2461\n",
      "           1      0.935     0.985     0.959     16113\n",
      "\n",
      "    accuracy                          0.927     18574\n",
      "   macro avg      0.893     0.767     0.813     18574\n",
      "weighted avg      0.924     0.927     0.921     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9245, F1=0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.833     0.538     0.654      2461\n",
      "           1      0.933     0.983     0.958     16112\n",
      "\n",
      "    accuracy                          0.925     18573\n",
      "   macro avg      0.883     0.761     0.806     18573\n",
      "weighted avg      0.920     0.925     0.917     18573\n",
      "\n",
      "Avg Accuracy: 0.9268108594172453\n",
      "Avg F1 Score: 0.9589232089818701\n",
      "Running Configuration 11: {'max_features': 10000, 'ngram_range': (2, 2)}\n",
      "Fold 1: Accuracy=0.8995, F1=0.9448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.837     0.301     0.442      2462\n",
      "           1      0.903     0.991     0.945     16112\n",
      "\n",
      "    accuracy                          0.900     18574\n",
      "   macro avg      0.870     0.646     0.694     18574\n",
      "weighted avg      0.894     0.900     0.878     18574\n",
      "\n",
      "Fold 2: Accuracy=0.9002, F1=0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.850     0.300     0.444      2462\n",
      "           1      0.903     0.992     0.945     16112\n",
      "\n",
      "    accuracy                          0.900     18574\n",
      "   macro avg      0.877     0.646     0.694     18574\n",
      "weighted avg      0.896     0.900     0.879     18574\n",
      "\n",
      "Fold 3: Accuracy=0.8989, F1=0.9446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.284     0.427      2461\n",
      "           1      0.901     0.993     0.945     16113\n",
      "\n",
      "    accuracy                          0.899     18574\n",
      "   macro avg      0.879     0.638     0.686     18574\n",
      "weighted avg      0.895     0.899     0.876     18574\n",
      "\n",
      "Fold 4: Accuracy=0.9011, F1=0.9457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.867     0.299     0.445      2461\n",
      "           1      0.903     0.993     0.946     16113\n",
      "\n",
      "    accuracy                          0.901     18574\n",
      "   macro avg      0.885     0.646     0.695     18574\n",
      "weighted avg      0.898     0.901     0.879     18574\n",
      "\n",
      "Fold 5: Accuracy=0.9004, F1=0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.855     0.299     0.444      2461\n",
      "           1      0.903     0.992     0.945     16112\n",
      "\n",
      "    accuracy                          0.900     18573\n",
      "   macro avg      0.879     0.646     0.694     18573\n",
      "weighted avg      0.896     0.900     0.879     18573\n",
      "\n",
      "Avg Accuracy: 0.9000419989973647\n",
      "Avg F1 Score: 0.9451201180421271\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "configs = [\n",
    "    {\"max_features\": 10000},\n",
    "    {\"max_features\": 5000},\n",
    "    {\"max_features\": 100000},\n",
    "    {\"max_features\": 500000},\n",
    "    {\"ngram_range\": (1, 2)},\n",
    "    {\"use_idf\": False},   \n",
    "    {\"stop_words\": None}, \n",
    "    {\"lowercase\": True},\n",
    "    {\"lowercase\": False},\n",
    "    {\"max_df\": 0.9},\n",
    "    {\"max_features\": 10000, \"ngram_range\": (2, 2)},\n",
    "]\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    print(f\"Running Configuration {i+1}: {config}\")\n",
    "    vectorizer = TfidfVectorizer(**config)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    acc = run_log_reg(X, y, vectorizer, model)\n",
    "    if  acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9980637",
   "metadata": {},
   "source": [
    "# Extreme Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72786bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True: 0, Pred: 1, Confidence: 1.00\n",
      "work great stay using outlet\n",
      "\n",
      "True: 0, Pred: 1, Confidence: 1.00\n",
      "heavy bulky easy use\n",
      "\n",
      "True: 0, Pred: 1, Confidence: 1.00\n",
      "useful easy use\n",
      "\n",
      "True: 1, Pred: 0, Confidence: 1.00\n",
      "dont waste money small wont latch\n",
      "\n",
      "True: 1, Pred: 0, Confidence: 1.00\n",
      "pay baby job perfectly waste money expensive webcam\n",
      "\n",
      "True: 0, Pred: 1, Confidence: 1.00\n",
      "needed new mouse wireless nice price work great burn battery ridiculous rate good value\n",
      "\n",
      "True: 0, Pred: 1, Confidence: 0.99\n",
      "work great large small city forget getting tv reception less populated area like state park people around antenna crank getting tv station get nothing even blue light lit thinking returning crank antenna disappointed\n",
      "\n",
      "True: 0, Pred: 1, Confidence: 0.99\n",
      "could great product better sticking remove tape replace tape\n",
      "\n",
      "True: 0, Pred: 1, Confidence: 0.99\n",
      "seemed great product mention anywhere would support video playback usb perhaps paid video personality sale page\n",
      "\n",
      "True: 0, Pred: 1, Confidence: 0.99\n",
      "thought great product however worked little week\n"
     ]
    }
   ],
   "source": [
    "# Transform X to TF-IDF features\n",
    "X_tfidf = vectorizer.transform(X)\n",
    "\n",
    "best_model.fit(X_tfidf, y)\n",
    "preds = best_model.predict(X_tfidf)\n",
    "\n",
    "# Find the most confident wrong predictions\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "errors = (preds != y)\n",
    "probs = best_model.predict_proba(X_tfidf)\n",
    "conf_scores = np.max(probs, axis=1)\n",
    "\n",
    "# Most confident incorrect predictions\n",
    "extreme_errors = np.argsort(-conf_scores[errors])[:10]\n",
    "\n",
    "for idx in np.where(errors)[0][extreme_errors]:\n",
    "    print(f\"\\nTrue: {y[idx]}, Pred: {preds[idx]}, Confidence: {conf_scores[idx]:.2f}\")\n",
    "    print(reviews_df.iloc[idx]['clean_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
